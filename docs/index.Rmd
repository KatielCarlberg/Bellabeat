---
title: "How Can a Wellness Technology Company Play It Smart? A Bellabeat Case Study"
author: "Katie Carlberg"
date: "2023-02-26"
output:
  html_document: default
  pdf_document: default
---

```{=html}
<style type="text/css">

body{background-color: DarkSalmon;
      font-size: 12px;
      color: White;
      font-family: "Times New Roman", Times, serif;
  }
td {  /* Table  */
  font-size: 8px;
  color: White;
  font-family: "Times New Roman", Times, serif;
}
h1.title {
  font-size: 38px;
  color: White;
  font-family: "Times New Roman", Times, serif;
}
h1 { /* Header 1 */
  font-size: 28px;
  color: White;
  font-family: "Times New Roman", Times, serif;
}
h2 { /* Header 2 */
    font-size: 22px;
  color: White;
  font-family: "Times New Roman", Times, serif;
}
h3 { /* Header 3 */
  font-size: 19px;
  font-family: "Times New Roman", Times, serif;
  color: Black;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r out.width = "200px", fig.align= 'center', echo= FALSE}
knitr::include_graphics("C:/Users/Dusk/Desktop/School/Projects/Bellabeat.png")
```

## Summary

### Bellabeat is a high-tech company that manufactures health-focused smart products. They offer stylish products for women that collect data on activity, sleep, stress, and reproductive health. The company was founded in 2013 by Urška Sršen and Sando Mur and has expanded quickly since, now with the possibility to become a greater player in the global smart device market.

### Today, we are going to be analyzing smart device data to gain insight into how consumers are using their existing smart devices. This, in turn, will help us make recommendations that will guide the marketing strategy for the company, focusing specifically on the Bellabeat App and Membership.

### The Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and make healthy decisions. The Bellabeat app connects to their line of smart wellness products.

### This case study follows the six-step data analysis process: [Ask](#ask), [Prepare](#prepare), [Process](#process), [Analyze](#analyze), [Share](#share), and [Act](#act).

## Step One: Ask {#ask}

### *Business Task*: Analyze competitor smart device (Fitbit) data to gain insight that will help guide the marketing strategy for Bellabeat in order to grow in the global market.

### *Primary stakeholders*: Urška Sršen and Sando Mur, co-founders of Bellabeat.

### *Secondary stakeholders*: Bellabeat marketing analytics team.

## Step Two: Prepare {#prepare}

### In order to prepare for analysis, we must first look at the attributes of our data, confirm it's usability, and then sort and filter it for ease of use in the coming steps.

### The dataset we will use is the [FitBit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit) dataset by Möbius. The data is generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.

### We can verify that the data is free to use without permission by observing in the metadata that a Creative Commons license has been applied to this work.

### **We can make some initial observations about the data using the ROCCC method:**

### The data is **Reliable** because we know exactly where it is coming from and how it was collected.

### The data is **Original** because we know that it is coming directly from the fitbit devices and not through a second or third party.

### The data is *nearly* **Comprehensive** because while it does contain minute levels of detail for many different categories, the sample size is small, and there are sizeable chunks missing across the board.

### The data is *not* **Current** because it only covers March to May of 2016. The habits and environment of smart device users could be different now.

### The data is **Cited** because we know it was gathered from fitbit users via Amazon, however we don't know anything more specific than that.

### **This data has limitations.**

### There are only thirty participants in this sample, and we do not have key demographic information for them such as age, gender, race, and location. Without knowing this information, it is possible that this data contains bias and does not represent the general population as a whole. Therefore, we may only make general recommendations based upon the limited information gathered from this dataset.

### **Sorting and Filtering**

### Because of the small sample size, I decided to use Microsoft Excel to first sort and filter the data files before moving on to the process phase. By creating pivot tables and graphs within Excel, I was able to make the following determinations:

### • There are actually 33 unique user IDs in the Daily Activity data sets, 24 unique IDs in the Sleep sets, 14 in the Heartrate set, and only 8 IDs in the Weight Log set. (Found by using the **=SUM(1/COUNTIF())** formula.)

### • All of the datasets we are using contain the same ID column, therefore we can merge and transform these tables for analysis.

### • The study is found to have lasted precisely 31 days from start to finish. (Using the **=DATEDIF()** formula.)

### • Because the dailyActivity_merged table includes the same data as dailyCalories, dailyIntensities, and dailySteps, we can disregard these sets for our analysis.

### • The hourly and minute breakdowns of the datasets will not give us enough valuable information to be able to make general recommendations, therefore we will not be using these in our analysis either.

## Step Three: Process {#process}

```{r out.width = "150px", fig.align= 'center', echo= FALSE}
knitr::include_graphics("C:/Users/Dusk/Desktop/School/Projects/Rlogo.svg")
```

### In order to analyze our data, we must first get it ready by cleaning and transforming the sets. This will give us the best possible data to then glean our results from.

### **For this task, I have chosen to use R.** The multitude of packages availble make this program ideal for cleaning and analyzing data.

### First we will install the packages needed for this project.

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
options(repos = c(CRAN = "https://cloud.r-project.org"))
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
knitr::include_graphics("C:/Users/Dusk/Desktop/School/Projects/installpcks.png")
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
install.packages("tidyverse")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("here")
install.packages("skimr")
install.packages("janitor")
install.packages("lubridate")
install.packages("readr")
install.packages("tidyr")
install.packages("magrittr")
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(here)
library(skimr)
library(janitor)
library(lubridate)
library(readr)
library(tidyr)
library(magrittr)
```

### Next, we will import our datasets as **Data Frames** with simplified names for ease of use.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
DailyActivity <- readr::read_csv("C:/Users/Dusk/Desktop/School/Projects/archive/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv")
Heartrate <- readr::read_csv("C:/Users/Dusk/Desktop/School/Projects/archive/Fitabase Data 4.12.16-5.12.16/heartrate_seconds_merged.csv")
SleepDay <- readr::read_csv("C:/Users/Dusk/Desktop/School/Projects/archive/Fitabase Data 4.12.16-5.12.16/sleepDay_merged.csv")
WeightLog <- readr::read_csv("C:/Users/Dusk/Desktop/School/Projects/archive/Fitabase Data 4.12.16-5.12.16/weightLogInfo_merged.csv")


```

### Now, we can preview the datasets by using the head() function.

```{r}
head(DailyActivity)
```

```{r}
head(Heartrate)
```

```{r}
head(SleepDay)
```

```{r}
head(WeightLog)
```

### We can see with the head() function that all of our dates are entered as character data types. In order to use this data for analysis, we will need to transform the character data into date data. To do this, we will use the lubridate package as follows:

```{r}
DailyActivity$date <- lubridate::mdy(DailyActivity$ActivityDate)

```

### Now we can verify with the glimpse() function that a new column has been added to our dataframe named "date" and that it is in fact, in a date format. We will repeat these steps for all four of our dataframes.

```{r}
dplyr::glimpse(DailyActivity)
```

```{r}
Heartrate$date <- lubridate::mdy_hms(Heartrate$Time)
SleepDay$date <- lubridate::mdy_hms(SleepDay$SleepDay)
WeightLog$date_time <- lubridate::mdy_hms(WeightLog$Date)

```

### Next, we will check the datasets for duplicates.

```{r}
sum(duplicated(DailyActivity))
sum(duplicated(Heartrate))
sum(duplicated(SleepDay))
sum(duplicated(WeightLog))
```

### Using the distinct() and drop_na() functions together, we can remove both the duplicates and the n/a entries from our datasets at the same time with the pipeline tool (%\>%).

```{r include=FALSE}
library(magrittr)
```

```{r}
DailyActivity <- DailyActivity %>%
  distinct() %>%
  drop_na()
Heartrate <- Heartrate %>%
  distinct() %>%
  drop_na()
SleepDay <- SleepDay %>%
  distinct() %>%
  drop_na()
WeightLog <- WeightLog %>%
  distinct() %>%
  drop_na()
```

### Let's check to see if it worked.

```{r}
sum(duplicated(SleepDay))
```

### Perfect.

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
